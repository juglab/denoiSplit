{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_checkpoint(ckpt_dir):\n",
    "    output = []\n",
    "    for filename in glob.glob(ckpt_dir + \"/*_best.ckpt\"):\n",
    "        output.append(filename)\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52206b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.model_type import ModelType\n",
    "if os.path.isdir(ckpt_dir):\n",
    "    config = load_config(ckpt_dir)\n",
    "else:\n",
    "    config = load_config(os.path.dirname(ckpt_dir))\n",
    "\n",
    "config = ml_collections.ConfigDict(config)\n",
    "old_image_size = None\n",
    "with config.unlocked():\n",
    "    try:\n",
    "        if config.model.model_type == ModelType.LadderVaeSepEncoder:\n",
    "            if 'use_random_for_missing_inp' not in config.model:\n",
    "                config.model.use_random_for_missing_inp =False\n",
    "            if 'learnable_merge_tensors' not in config.model:\n",
    "                config.model.learnable_merge_tensors = False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if 'test_fraction' not in config.training:\n",
    "        config.training.test_fraction =0.0\n",
    "        \n",
    "    if 'datadir' not in config:\n",
    "        config.datadir = ''\n",
    "    if 'encoder' not in config.model:\n",
    "        config.model.encoder = ml_collections.ConfigDict()\n",
    "        assert 'decoder' not in config.model\n",
    "        config.model.decoder = ml_collections.ConfigDict()\n",
    "    \n",
    "        config.model.encoder.dropout = config.model.dropout\n",
    "        config.model.decoder.dropout = config.model.dropout\n",
    "        config.model.encoder.blocks_per_layer = config.model.blocks_per_layer\n",
    "        config.model.decoder.blocks_per_layer = config.model.blocks_per_layer\n",
    "        config.model.encoder.n_filters = config.model.n_filters\n",
    "        config.model.decoder.n_filters = config.model.n_filters\n",
    "        \n",
    "    if 'multiscale_retain_spatial_dims' not in config.model.decoder:\n",
    "        config.model.decoder.multiscale_retain_spatial_dims = False\n",
    "        \n",
    "    if 'res_block_kernel' not in config.model.encoder:\n",
    "        config.model.encoder.res_block_kernel = 3\n",
    "        assert 'res_block_kernel' not in config.model.decoder\n",
    "        config.model.decoder.res_block_kernel = 3\n",
    "    \n",
    "    if 'res_block_skip_padding' not in config.model.encoder:\n",
    "        config.model.encoder.res_block_skip_padding = False\n",
    "        assert 'res_block_skip_padding' not in config.model.decoder\n",
    "        config.model.decoder.res_block_skip_padding = False\n",
    "    \n",
    "    if config.data.data_type == DataType.CustomSinosoid:\n",
    "        if 'max_vshift_factor' not in config.data:\n",
    "            config.data.max_vshift_factor = config.data.max_shift_factor\n",
    "            config.data.max_hshift_factor = 0\n",
    "        if 'encourage_non_overlap_single_channel' not in config.data:\n",
    "            config.data.encourage_non_overlap_single_channel = False\n",
    "        \n",
    "    \n",
    "   \n",
    "    if 'skip_bottom_layers_count' in config.model:\n",
    "        config.model.skip_bottom_layers_count = 0\n",
    "        \n",
    "    if 'logvar_lowerbound' not in config.model:\n",
    "        config.model.logvar_lowerbound = None\n",
    "    if 'train_aug_rotate' not in config.data:\n",
    "        config.data.train_aug_rotate = False\n",
    "    if 'multiscale_lowres_separate_branch' not in config.model:\n",
    "        config.model.multiscale_lowres_separate_branch = False\n",
    "    if 'multiscale_retain_spatial_dims' not in config.model:\n",
    "        config.model.multiscale_retain_spatial_dims = False\n",
    "    config.data.train_aug_rotate=False\n",
    "    \n",
    "    if 'randomized_channels' not in config.data:\n",
    "        config.data.randomized_channels = False\n",
    "        \n",
    "    if 'predict_logvar' not in config.model:\n",
    "        config.model.predict_logvar=None\n",
    "    \n",
    "    if 'batchnorm' in config.model and 'batchnorm' not in config.model.encoder:\n",
    "        assert 'batchnorm' not in config.model.decoder\n",
    "        config.model.decoder.batchnorm = config.model.batchnorm\n",
    "        config.model.encoder.batchnorm = config.model.batchnorm\n",
    "    if 'conv2d_bias' not in config.model.decoder:\n",
    "        config.model.decoder.conv2d_bias = True\n",
    "        \n",
    "\n",
    "    if custom_image_size is not None:\n",
    "        old_image_size = config.data.image_size\n",
    "        config.data.image_size = custom_image_size\n",
    "    if image_size_for_grid_centers is not None:\n",
    "        old_grid_size = config.data.get('grid_size', \"grid_size not present\")\n",
    "        config.data.grid_size = image_size_for_grid_centers\n",
    "        config.data.val_grid_size = image_size_for_grid_centers\n",
    "\n",
    "    if use_deterministic_grid is not None:\n",
    "        config.data.deterministic_grid = use_deterministic_grid\n",
    "    if threshold is not None:\n",
    "        config.data.threshold = threshold\n",
    "    if val_repeat_factor is not None:\n",
    "        config.training.val_repeat_factor = val_repeat_factor\n",
    "    config.model.mode_pred = not compute_kl_loss\n",
    "\n",
    "print(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DivNoising",
   "language": "python",
   "name": "divnoising"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
