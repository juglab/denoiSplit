{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b6af96",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This is to be used for loading the data loader and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if image_size_for_grid_centers is None:\n",
    "#     image_size_for_grid_centers = config.data.image_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd4469",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # from denoisplit.data_loader.overlapping_dloader import get_overlapping_dset\n",
    "# from denoisplit.data_loader.vanilla_dloader import MultiChDloader\n",
    "# from denoisplit.data_loader.lc_multich_dloader import LCMultiChDloader\n",
    "# from denoisplit.core.data_split_type import DataSplitType\n",
    "# from denoisplit.data_loader.single_channel.single_channel_dloader import SingleChannelDloader\n",
    "# from denoisplit.data_loader.single_channel.single_channel_mc_dloader import SingleChannelMSDloader\n",
    "# from denoisplit.data_loader.pavia2_3ch_dloader import Pavia2ThreeChannelDloader\n",
    "from denoisplit.data_loader.patch_index_manager import GridAlignement\n",
    "# from denoisplit.data_loader.ht_iba1_ki67_dloader import IBA1Ki67DataLoader\n",
    "# from denoisplit.data_loader.multifile_dset import MultiFileDset\n",
    "\n",
    "padding_kwargs = {\n",
    "    'mode':config.data.get('padding_mode','constant'),\n",
    "}\n",
    "\n",
    "if padding_kwargs['mode'] == 'constant':\n",
    "    padding_kwargs['constant_values'] = config.data.get('padding_value',0)\n",
    "\n",
    "dloader_kwargs = {'overlapping_padding_kwargs':padding_kwargs, \n",
    "                  'grid_alignment': GridAlignement.Center}\n",
    "# if 'multiscale_lowres_count' in config.data and config.data.multiscale_lowres_count is not None:\n",
    "#     dloader_kwargs['num_scales'] = config.data.multiscale_lowres_count\n",
    "#     dloader_kwargs['padding_kwargs'] = padding_kwargs\n",
    "\n",
    "\n",
    "# if config.data.data_type == DataType.SemiSupBloodVesselsEMBL:\n",
    "#     if 'multiscale_lowres_count' in config.data and config.data.multiscale_lowres_count is not None:\n",
    "#         data_class = get_overlapping_dset(SingleChannelMSDloader)\n",
    "#         dloader_kwargs['num_scales'] = config.data.multiscale_lowres_count\n",
    "#         dloader_kwargs['padding_kwargs'] = padding_kwargs\n",
    "#     else:\n",
    "#         data_class = get_overlapping_dset(SingleChannelDloader)\n",
    "# elif config.data.data_type == DataType.Pavia2:\n",
    "#     data_class = get_overlapping_dset(Pavia2ThreeChannelDloader)\n",
    "\n",
    "# elif config.data.data_type == DataType.HTIba1Ki67 and config.model.model_type in [ModelType.LadderVaeMultiDataSet, \n",
    "#                                     ModelType.LadderVaeMultiDatasetMultiBranch, ModelType.LadderVaeMultiDatasetMultiOptim]:\n",
    "#     data_class = IBA1Ki67DataLoader\n",
    "\n",
    "# elif config.data.data_type in [DataType.TavernaSox2Golgi, DataType.ExpMicroscopyV2]:\n",
    "#     if 'num_scales' in dloader_kwargs:\n",
    "#         del dloader_kwargs['num_scales']\n",
    "#     data_class = MultiFileDset\n",
    "\n",
    "# elif 'multiscale_lowres_count' in config.data and config.data.multiscale_lowres_count is not None:\n",
    "#     data_class = LCMultiChDloader\n",
    "\n",
    "# elif config.model.model_type==ModelType.AutoRegresiveLadderVAE:\n",
    "#     from denoisplit.data_loader.autoregressive_dloader import AutoRegressiveDloader\n",
    "#     data_class = AutoRegressiveDloader\n",
    "# else:\n",
    "#     # data_class = get_overlapping_dset(MultiChDloader)\n",
    "#     data_class = MultiChDloader\n",
    "\n",
    "# if config.data.data_type in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve, \n",
    "#                              DataType.AllenCellMito,DataType.SeparateTiffData,\n",
    "#                             DataType.SemiSupBloodVesselsEMBL, DataType.BSD68]:\n",
    "#     datapath = data_dir\n",
    "# elif config.data.data_type == DataType.OptiMEM100_014:\n",
    "#     datapath = os.path.join(data_dir, 'OptiMEM100x014.tif')\n",
    "# elif config.data.data_type == DataType.Prevedel_EMBL:\n",
    "#     datapath = os.path.join(data_dir, 'MS14__z0_8_sl4_fr10_p_10.1_lz510_z13_bin5_00001.tif')\n",
    "# # elif config.data.data_type == DataType.Convallaria:\n",
    "# #     datapath = os.path.join(data_dir, '20190520_tl_25um_50msec_05pc_488_130EM_Conv_withChannel.tif')\n",
    "# else:\n",
    "#     datapath = data_dir\n",
    "\n",
    "# normalized_input = config.data.normalized_input\n",
    "# use_one_mu_std = config.data.use_one_mu_std\n",
    "# train_aug_rotate = config.data.train_aug_rotate\n",
    "# enable_random_cropping = False #config.data.deterministic_grid is False\n",
    "# grid_alignment = GridAlignement.Center\n",
    "# print(data_class)\n",
    "\n",
    "# train_dset = data_class(\n",
    "#                 config.data,\n",
    "#                 datapath,\n",
    "#                 datasplit_type=DataSplitType.Train,\n",
    "#                 val_fraction=config.training.val_fraction,\n",
    "#                 test_fraction=config.training.test_fraction,\n",
    "#                 normalized_input=normalized_input,\n",
    "#                 use_one_mu_std=use_one_mu_std,\n",
    "#                 enable_rotation_aug=train_aug_rotate,\n",
    "#                 enable_random_cropping=enable_random_cropping,\n",
    "#                 grid_alignment=grid_alignment,\n",
    "#                 **dloader_kwargs)\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# max_val = train_dset.get_max_val()\n",
    "\n",
    "# if subdset_type is not None:\n",
    "#     with config.unlocked():\n",
    "#         config.data.subdset_type = subdset_type\n",
    "#         assert eval_datasplit_type != DataSplitType.Train\n",
    "\n",
    "# val_dset = data_class(\n",
    "#                 config.data,\n",
    "#                 datapath,\n",
    "#                 datasplit_type=eval_datasplit_type,\n",
    "#                 val_fraction=config.training.val_fraction,\n",
    "#                 test_fraction=config.training.test_fraction,\n",
    "#                 normalized_input=normalized_input,\n",
    "#                 use_one_mu_std=use_one_mu_std,\n",
    "#                 enable_rotation_aug=False,  # No rotation aug on validation\n",
    "#                 enable_random_cropping=False,\n",
    "#                 # No random cropping on validation. Validation is evaluated on determistic grids\n",
    "#                 grid_alignment=grid_alignment,\n",
    "#                 max_val=max_val,\n",
    "#                 **dloader_kwargs\n",
    "                \n",
    "#             )\n",
    "\n",
    "# # For normalizing, we should be using the training data's mean and std.\n",
    "# mean_val, std_val = train_dset.compute_mean_std()\n",
    "# train_dset.set_mean_std(mean_val, std_val)\n",
    "# val_dset.set_mean_std(mean_val, std_val)\n",
    "\n",
    "\n",
    "# if evaluate_train:\n",
    "#     val_dset = train_dset\n",
    "# data_mean, data_std = train_dset.get_mean_std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.training import create_dataset\n",
    "train_dset, val_dset = create_dataset(config, data_dir, eval_datasplit_type=eval_datasplit_type,\n",
    "                                      kwargs_dict=dloader_kwargs)\n",
    "data_mean, data_std = train_dset.get_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/ashesh.ashesh/training/disentangle/2301/D3-M10-S0-L3/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8e48d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with config.unlocked():\n",
    "    if old_image_size is not None:\n",
    "        config.data.image_size = old_image_size\n",
    "\n",
    "# if config.data.target_separate_normalization is True:\n",
    "#     mean_fr_model, std_fr_model = train_dset.compute_individual_mean_std()\n",
    "# else:\n",
    "#     mean_fr_model, std_fr_model = train_dset.get_mean_std()\n",
    "\n",
    "# if config.model.model_type == ModelType.LadderVaeSemiSupervised:\n",
    "#     mean_fr_model = mean_fr_model[None]\n",
    "#     std_fr_model = std_fr_model[None]\n",
    "\n",
    "###### Create the input and target mean and std for feeding to the model\n",
    "mean_dict = {'input': None, 'target': None}\n",
    "std_dict = {'input': None, 'target': None}\n",
    "inp_fr_mean, inp_fr_std = train_dset.get_mean_std()\n",
    "mean_sq = inp_fr_mean.squeeze()\n",
    "std_sq = inp_fr_std.squeeze()\n",
    "assert mean_sq[0] == mean_sq[1] and len(mean_sq) == config.data.get('num_channels',2)\n",
    "assert std_sq[0] == std_sq[1] and len(std_sq) == config.data.get('num_channels',2)\n",
    "mean_dict['input'] = np.mean(inp_fr_mean, axis=1, keepdims=True)\n",
    "std_dict['input'] = np.mean(inp_fr_std, axis=1, keepdims=True)\n",
    "\n",
    "if config.data.target_separate_normalization is True:\n",
    "    target_data_mean, target_data_std = train_dset.compute_individual_mean_std()\n",
    "else:\n",
    "    target_data_mean, target_data_std = train_dset.get_mean_std()\n",
    "\n",
    "mean_dict['target'] = target_data_mean\n",
    "std_dict['target'] = target_data_std\n",
    "###### \n",
    "  \n",
    "model = create_model(config, mean_dict,std_dict)\n",
    "if os.path.isdir(ckpt_dir):\n",
    "    ckpt_fpath = get_best_checkpoint(ckpt_dir)\n",
    "else:\n",
    "    assert os.path.isfile(ckpt_dir)\n",
    "    ckpt_fpath = ckpt_dir\n",
    "\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model.eval()\n",
    "_= model.cuda()\n",
    "\n",
    "model.set_params_to_same_device_as(torch.Tensor(1).cuda())\n",
    "\n",
    "print('Loading from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679042e0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model has {count_parameters(model)/1000_000:.3f}M parameters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
