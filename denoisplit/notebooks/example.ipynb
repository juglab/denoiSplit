{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781639b7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# denoiSplit: joint splitting and unsupervised denoising\n",
    "In this notebook, we tackle the problem of joint splitting and unsupervised denoising, which has a usecase with fluorescence microscopy. From a technical perspective, given a noisy image $x$, the goal is to predict two images $c_1$ and $c_2$ such that $x = c_1 + c_2$. In other words, we have a superimposed image $x$ and we want to predict the denoised estimates of the constituent images $c_1$ and $c_2$. It is important to note that the network is trained with noisy data and the denoising is done in a unsupervised manner. \n",
    "\n",
    "For this, we will use [denoiSplit](https://arxiv.org/pdf/2403.11854.pdf), a recently developed approach for this task. In this notebook we train denoiSplit and later evaluate it on one validation frame. The overall schema for denoiSplit is shown below:\n",
    "<!-- Insert a figure -->\n",
    "<!-- ![Schema](teaser.png) -->\n",
    "<img src=\"teaser.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "\n",
    "Here, we look at CCPs (clathrin-coated pits) vs ER (Endoplasmic reticulum) task, one of the tasks tackled by denoiSplit which is generated from [BioSR](https://figshare.com/articles/dataset/BioSR/13264793) dataset. For this task, the noise is synthetically added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a useful library developed by Google for maintaining the ML configs.\n",
    "! pip install ml-collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476515a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Mandatory actions\n",
    "<div class=\"alert alert-danger\">\n",
    "1. Set your python kernel to <code>careamics</code> <br>\n",
    "2. Set the <code>data_dir</code> to the path where the BioSR dataset is present. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debc036",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Set directories \n",
    "In the next cell, we enumerate the necessary fields for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca640ca1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/group/jug/ashesh/data/BioSR/\"  # FILL IN THE PATH TO THE DATA DIRECTORY\n",
    "work_dir = \".\"\n",
    "tensorboard_log_dir = os.path.join(work_dir, \"tensorboard_logs\")\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "from denoisplit.analysis.plot_utils import clean_ax\n",
    "from denoisplit.configs.biosr_config import get_config\n",
    "from denoisplit.training import create_dataset\n",
    "from denoisplit.nets.model_utils import create_model\n",
    "from denoisplit.core.metric_monitor import MetricMonitor\n",
    "from denoisplit.scripts.run import get_mean_std_dict_for_model\n",
    "from denoisplit.core.data_split_type import DataSplitType\n",
    "from denoisplit.scripts.evaluate import get_highsnr_data\n",
    "from denoisplit.analysis.mmse_prediction import get_dset_predictions\n",
    "from denoisplit.data_loader.patch_index_manager import GridAlignement\n",
    "from denoisplit.scripts.evaluate import avg_range_inv_psnr, compute_multiscale_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b5159",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Config \n",
    "<div class=\"alert alert-block alert-warning\"><h3>\n",
    "    Several Things to try (try some ;) ):</h3>\n",
    "    <ol>\n",
    "        <li>Run once with unchanged config to see the performance. </li>\n",
    "        <li>Increase the noise (double the gaussian noise?) and see how performance degrades. </li>\n",
    "        <li> Increase the max_epochs, if you want to get better performance. </li>\n",
    "        <li> For faster training ( but compromising on performance), reduce the number of hierarchy levels and/or the channel count by modifying <em>config.model.z_dims</em>.</li> \n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29c8ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# load the default config.\n",
    "config = get_config()\n",
    "# Channge the noise level\n",
    "config.data.poisson_noise_factor = (\n",
    "    1000  # 1000 is the default value. noise increases with the value.\n",
    ")\n",
    "config.data.synthetic_gaussian_scale = (\n",
    "    5000  # 5000 is the default value. noise increases with the value.\n",
    ")\n",
    "\n",
    "# change the number of hierarchy levels.\n",
    "config.model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "# change the training parameters\n",
    "config.training.lr = 3e-3\n",
    "config.training.max_epochs = 10\n",
    "config.training.batch_size = 32\n",
    "config.training.num_workers = 4\n",
    "\n",
    "config.workdir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb11fd",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the dataset and pytorch dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39660aee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_dset, val_dset = create_dataset(config, data_dir)\n",
    "mean_dict, std_dict = get_mean_std_dict_for_model(config, train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef74b46",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "batch_size = config.training.batch_size\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03002ea2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the model.\n",
    "Here, we instantiate the [denoiSplit model](https://arxiv.org/pdf/2403.11854.pdf). For simplicity, we have disabled the noise model. For enabling the noise model, one would additionally have to train a denoiser. The next step would be to create a noise model using the noisy data and the corresponding denoised predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5509b33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = create_model(config, mean_dict, std_dict)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af80f83",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfaf11",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# logger = TensorBoardLogger(tensorboard_log_dir, name=\"\", version=\"\", default_hp_metric=False)\n",
    "logger = None\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config.training.max_epochs,\n",
    "    gradient_clip_val=(\n",
    "        None\n",
    "        if model.automatic_optimization == False\n",
    "        else config.training.grad_clip_norm_value\n",
    "    ),\n",
    "    logger=logger,\n",
    "    precision=config.training.precision,\n",
    ")\n",
    "trainer.fit(model, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74513b03",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd234250",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ = model.cuda()\n",
    "eval_frame_idx = 0\n",
    "# reducing the data, just for speed\n",
    "val_dset.reduce_data(t_list=[eval_frame_idx])\n",
    "mmse_count = 10\n",
    "overlapping_padding_kwargs = {\n",
    "    \"mode\": config.data.get(\"padding_mode\", \"constant\"),\n",
    "}\n",
    "if overlapping_padding_kwargs[\"mode\"] == \"constant\":\n",
    "    overlapping_padding_kwargs[\"constant_values\"] = config.data.get(\"padding_value\", 0)\n",
    "val_dset.set_img_sz(\n",
    "    128,\n",
    "    32,\n",
    "    grid_alignment=GridAlignement.Center,\n",
    "    overlapping_padding_kwargs=overlapping_padding_kwargs,\n",
    ")\n",
    "\n",
    "# MMSE prediction\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = (\n",
    "    get_dset_predictions(\n",
    "        model,\n",
    "        val_dset,\n",
    "        batch_size,\n",
    "        num_workers=config.training.num_workers,\n",
    "        mmse_count=mmse_count,\n",
    "        model_type=config.model.model_type,\n",
    "    )\n",
    ")\n",
    "\n",
    "# One sample prediction\n",
    "pred1_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")\n",
    "# One sample prediction\n",
    "pred2_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287f57c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Stich the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed1e7a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from denoisplit.analysis.stitch_prediction import stitch_predictions\n",
    "\n",
    "pred = stitch_predictions(pred_tiled, val_dset)\n",
    "\n",
    "\n",
    "# ignore pixels at the [right/bottom] boundary.\n",
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while (\n",
    "        pred[\n",
    "            0,\n",
    "            -ignored_pixels:,\n",
    "            -ignored_pixels:,\n",
    "        ].std()\n",
    "        == 0\n",
    "    ):\n",
    "        ignored_pixels += 1\n",
    "    ignored_pixels -= 1\n",
    "    return ignored_pixels\n",
    "\n",
    "\n",
    "actual_ignored_pixels = print_ignored_pixels()\n",
    "pred = pred[:, :-actual_ignored_pixels, :-actual_ignored_pixels]\n",
    "pred1 = stitch_predictions(pred1_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]\n",
    "pred2 = stitch_predictions(pred2_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518d1f5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "highres_data = get_highsnr_data(config, data_dir, DataSplitType.Val)\n",
    "\n",
    "highres_data = highres_data[\n",
    "    eval_frame_idx : eval_frame_idx + 1,\n",
    "    :-actual_ignored_pixels,\n",
    "    :-actual_ignored_pixels,\n",
    "]\n",
    "\n",
    "noisy_data = val_dset._noise_data[..., 1:] + val_dset._data\n",
    "noisy_data = noisy_data[..., :-actual_ignored_pixels, :-actual_ignored_pixels, :]\n",
    "model_input = np.mean(noisy_data, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f921be4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Qualitative performance on a random crop\n",
    "denoiSplit is capable of sampling from a learned posterior.\n",
    "Here we show full input frame and a randomly cropped input (300*300),\n",
    "two corresponding prediction samples, the difference between the two samples (S1−S2),\n",
    "the MMSE prediction, and otherwise unused high SNR microscopy crop. \n",
    "The MMSE predictions are computed by averaging 10 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_str(ax_, txt):\n",
    "    \"\"\"\n",
    "    Add psnr string to the axes\n",
    "    \"\"\"\n",
    "    textstr = txt\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"gray\", alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax_.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        textstr,\n",
    "        transform=ax_.transAxes,\n",
    "        fontsize=11,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=props,\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "\n",
    "ncols = 7\n",
    "nrows = 2\n",
    "sz = 300\n",
    "hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "ax[0, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "rect = patches.Rectangle((ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "ax[0, 0].add_patch(rect)\n",
    "ax[1, 0].imshow(model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\")\n",
    "add_str(ax[0, 0], \"Full Input Frame\")\n",
    "add_str(ax[1, 0], \"Random Input Crop\")\n",
    "\n",
    "ax[0, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "diff = pred2 - pred1\n",
    "ax[0, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "ax[1, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\")\n",
    "\n",
    "ax[0, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "\n",
    "ax[0, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "ax[0, 0].set_title(\"Model Input\", size=13)\n",
    "ax[0, 1].set_title(\"Target\", size=13)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=13)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=13)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=13)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=13)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=13)\n",
    "\n",
    "twinx = ax[0, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 1\", size=13)\n",
    "clean_ax(twinx)\n",
    "twinx = ax[1, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 2\", size=13)\n",
    "clean_ax(twinx)\n",
    "clean_ax(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884583e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Qualitative performance on multiple random crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab248e8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nimgs = 3\n",
    "ncols = 7\n",
    "nrows = 2 * nimgs\n",
    "sz = 300\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "\n",
    "for img_idx in range(nimgs):\n",
    "    hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "    ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "    ax[2 * img_idx, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "    rect = patches.Rectangle(\n",
    "        (ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    "    )\n",
    "    ax[2 * img_idx, 0].add_patch(rect)\n",
    "    ax[2 * img_idx + 1, 0].imshow(\n",
    "        model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\"\n",
    "    )\n",
    "    add_str(ax[2 * img_idx, 0], \"Full Input Frame\")\n",
    "    add_str(ax[2 * img_idx + 1, 0], \"Random Input Crop\")\n",
    "\n",
    "    ax[2 * img_idx, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    diff = pred2 - pred1\n",
    "    ax[2 * img_idx, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "    ax[2 * img_idx + 1, 4].imshow(\n",
    "        diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    twinx = ax[2 * img_idx, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 1\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "    twinx = ax[2 * img_idx + 1, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 2\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "ax[0, 0].set_title(\"Model Input\", size=15)\n",
    "ax[0, 1].set_title(\"Target\", size=15)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=15)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=15)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=15)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=15)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=15)\n",
    "\n",
    "clean_ax(ax)\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63530a5a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Quantitative performance\n",
    "We evaluate on two metrics, Multiscale SSIM and PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4575b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tar = mean_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "std_tar = std_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "pred_unnorm = pred * std_tar + mean_tar\n",
    "\n",
    "psnr_list = [\n",
    "    avg_range_inv_psnr(highres_data[..., i].copy(), pred_unnorm[..., i].copy())\n",
    "    for i in range(highres_data.shape[-1])\n",
    "]\n",
    "ssim_list = compute_multiscale_ssim(highres_data.copy(), pred_unnorm.copy())\n",
    "print(\"Metric: Ch1\\t Ch2\")\n",
    "print(f\"PSNR  : {psnr_list[0]:.2f}\\t {psnr_list[1]:.2f}\")\n",
    "print(f\"MS-SSIM  : {ssim_list[0]:.3f}\\t {ssim_list[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
