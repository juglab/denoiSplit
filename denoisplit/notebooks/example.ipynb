{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781639b7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# denoiSplit: joint splitting and unsupervised denoising\n",
    "In this notebook, we tackle the problem of joint splitting and unsupervised denoising, which has a usecase with fluorescence microscopy. From a technical perspective, given a noisy image $x$, the goal is to predict two images $c_1$ and $c_2$ such that $x = c_1 + c_2$. In other words, we have a superimposed image $x$ and we want to predict the denoised estimates of the constituent images $c_1$ and $c_2$. It is important to note that the network is trained with noisy data and the denoising is done in a unsupervised manner. \n",
    "\n",
    "For this, we will use [denoiSplit](https://arxiv.org/pdf/2403.11854.pdf), a recently developed approach for this task. In this notebook we train denoiSplit and later evaluate it on one validation frame. The overall schema for denoiSplit is shown below:\n",
    "<!-- Insert a figure -->\n",
    "<!-- ![Schema](teaser.png) -->\n",
    "<img src=\"teaser.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "\n",
    "Here, we look at CCPs (clathrin-coated pits) vs ER (Endoplasmic reticulum) task, one of the tasks tackled by denoiSplit which is generated from [BioSR](https://figshare.com/articles/dataset/BioSR/13264793) dataset. For this task, the noise is synthetically added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a useful library developed by Google for maintaining the ML configs.\n",
    "! pip install ml-collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476515a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Mandatory actions\n",
    "<div class=\"alert alert-danger\">\n",
    "1. Set your python kernel to <code>careamics</code> <br>\n",
    "2. Set the <code>data_dir</code> to the path where the BioSR dataset is present. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debc036",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Set directories \n",
    "In the next cell, we enumerate the necessary fields for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca640ca1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/group/jug/ashesh/data/BioSR/\"  # FILL IN THE PATH TO THE DATA DIRECTORY\n",
    "work_dir = \".\"\n",
    "tensorboard_log_dir = os.path.join(work_dir, \"tensorboard_logs\")\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "from denoisplit.analysis.plot_utils import clean_ax\n",
    "from denoisplit.configs.biosr_config import get_config\n",
    "from denoisplit.training import create_dataset\n",
    "from denoisplit.nets.model_utils import create_model\n",
    "from denoisplit.core.metric_monitor import MetricMonitor\n",
    "from denoisplit.scripts.run import get_mean_std_dict_for_model\n",
    "from denoisplit.core.data_split_type import DataSplitType\n",
    "from denoisplit.scripts.evaluate import get_highsnr_data\n",
    "from denoisplit.analysis.mmse_prediction import get_dset_predictions\n",
    "from denoisplit.data_loader.patch_index_manager import GridAlignement\n",
    "from denoisplit.scripts.evaluate import avg_range_inv_psnr, compute_multiscale_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b5159",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Config \n",
    "<div class=\"alert alert-block alert-warning\"><h3>\n",
    "    Several Things to try (try some ;) ):</h3>\n",
    "    <ol>\n",
    "        <li>Run once with unchanged config to see the performance. </li>\n",
    "        <li>Increase the noise (double the gaussian noise?) and see how performance degrades. </li>\n",
    "        <li> Increase the max_epochs, if you want to get better performance. </li>\n",
    "        <li> For faster training ( but compromising on performance), reduce the number of hierarchy levels and/or the channel count by modifying <em>config.model.z_dims</em>.</li> \n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29c8ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# load the default config.\n",
    "config = get_config()\n",
    "# Channge the noise level\n",
    "config.data.poisson_noise_factor = (\n",
    "    1000  # 1000 is the default value. noise increases with the value.\n",
    ")\n",
    "config.data.synthetic_gaussian_scale = (\n",
    "    5000  # 5000 is the default value. noise increases with the value.\n",
    ")\n",
    "\n",
    "# change the number of hierarchy levels.\n",
    "config.model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "# change the training parameters\n",
    "config.training.lr = 3e-3\n",
    "config.training.max_epochs = 10\n",
    "config.training.batch_size = 32\n",
    "config.training.num_workers = 4\n",
    "\n",
    "config.workdir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb11fd",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the dataset and pytorch dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39660aee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_dset, val_dset = create_dataset(config, data_dir)\n",
    "mean_dict, std_dict = get_mean_std_dict_for_model(config, train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef74b46",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "batch_size = config.training.batch_size\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03002ea2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the model.\n",
    "Here, we instantiate the [denoiSplit model](https://arxiv.org/pdf/2403.11854.pdf). For simplicity, we have disabled the noise model. For enabling the noise model, one would additionally have to train a denoiser. The next step would be to create a noise model using the noisy data and the corresponding denoised predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5509b33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = create_model(config, mean_dict, std_dict)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af80f83",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfaf11",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# logger = TensorBoardLogger(tensorboard_log_dir, name=\"\", version=\"\", default_hp_metric=False)\n",
    "logger = None\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config.training.max_epochs,\n",
    "    gradient_clip_val=(\n",
    "        None\n",
    "        if model.automatic_optimization == False\n",
    "        else config.training.grad_clip_norm_value\n",
    "    ),\n",
    "    logger=logger,\n",
    "    precision=config.training.precision,\n",
    ")\n",
    "trainer.fit(model, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74513b03",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd234250",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ = model.cuda()\n",
    "eval_frame_idx = 0\n",
    "# reducing the data, just for speed\n",
    "val_dset.reduce_data(t_list=[eval_frame_idx])\n",
    "mmse_count = 10\n",
    "overlapping_padding_kwargs = {\n",
    "    \"mode\": config.data.get(\"padding_mode\", \"constant\"),\n",
    "}\n",
    "if overlapping_padding_kwargs[\"mode\"] == \"constant\":\n",
    "    overlapping_padding_kwargs[\"constant_values\"] = config.data.get(\"padding_value\", 0)\n",
    "val_dset.set_img_sz(\n",
    "    128,\n",
    "    32,\n",
    "    grid_alignment=GridAlignement.Center,\n",
    "    overlapping_padding_kwargs=overlapping_padding_kwargs,\n",
    ")\n",
    "\n",
    "# MMSE prediction\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = (\n",
    "    get_dset_predictions(\n",
    "        model,\n",
    "        val_dset,\n",
    "        batch_size,\n",
    "        num_workers=config.training.num_workers,\n",
    "        mmse_count=mmse_count,\n",
    "        model_type=config.model.model_type,\n",
    "    )\n",
    ")\n",
    "\n",
    "# One sample prediction\n",
    "pred1_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")\n",
    "# One sample prediction\n",
    "pred2_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287f57c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Stich the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed1e7a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from denoisplit.analysis.stitch_prediction import stitch_predictions\n",
    "\n",
    "pred = stitch_predictions(pred_tiled, val_dset)\n",
    "\n",
    "\n",
    "# ignore pixels at the [right/bottom] boundary.\n",
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while (\n",
    "        pred[\n",
    "            0,\n",
    "            -ignored_pixels:,\n",
    "            -ignored_pixels:,\n",
    "        ].std()\n",
    "        == 0\n",
    "    ):\n",
    "        ignored_pixels += 1\n",
    "    ignored_pixels -= 1\n",
    "    return ignored_pixels\n",
    "\n",
    "\n",
    "actual_ignored_pixels = print_ignored_pixels()\n",
    "pred = pred[:, :-actual_ignored_pixels, :-actual_ignored_pixels]\n",
    "pred1 = stitch_predictions(pred1_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]\n",
    "pred2 = stitch_predictions(pred2_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518d1f5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "highres_data = get_highsnr_data(config, data_dir, DataSplitType.Val)\n",
    "\n",
    "highres_data = highres_data[\n",
    "    eval_frame_idx : eval_frame_idx + 1,\n",
    "    :-actual_ignored_pixels,\n",
    "    :-actual_ignored_pixels,\n",
    "]\n",
    "\n",
    "noisy_data = val_dset._noise_data[..., 1:] + val_dset._data\n",
    "noisy_data = noisy_data[..., :-actual_ignored_pixels, :-actual_ignored_pixels, :]\n",
    "model_input = np.mean(noisy_data, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f921be4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Qualitative performance on a random crop\n",
    "denoiSplit is capable of sampling from a learned posterior.\n",
    "Here we show full input frame and a randomly cropped input (300*300),\n",
    "two corresponding prediction samples, the difference between the two samples (S1âˆ’S2),\n",
    "the MMSE prediction, and otherwise unused high SNR microscopy crop. \n",
    "The MMSE predictions are computed by averaging 10 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_str(ax_, txt):\n",
    "    \"\"\"\n",
    "    Add psnr string to the axes\n",
    "    \"\"\"\n",
    "    textstr = txt\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"gray\", alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax_.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        textstr,\n",
    "        transform=ax_.transAxes,\n",
    "        fontsize=11,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=props,\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "\n",
    "ncols = 7\n",
    "nrows = 2\n",
    "sz = 300\n",
    "hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "ax[0, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "rect = patches.Rectangle((ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "ax[0, 0].add_patch(rect)\n",
    "ax[1, 0].imshow(model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\")\n",
    "add_str(ax[0, 0], \"Full Input Frame\")\n",
    "add_str(ax[1, 0], \"Random Input Crop\")\n",
    "\n",
    "ax[0, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "diff = pred2 - pred1\n",
    "ax[0, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "ax[1, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\")\n",
    "\n",
    "ax[0, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "\n",
    "ax[0, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "ax[0, 0].set_title(\"Model Input\", size=13)\n",
    "ax[0, 1].set_title(\"Target\", size=13)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=13)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=13)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=13)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=13)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=13)\n",
    "\n",
    "twinx = ax[0, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 1\", size=13)\n",
    "clean_ax(twinx)\n",
    "twinx = ax[1, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 2\", size=13)\n",
    "clean_ax(twinx)\n",
    "clean_ax(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884583e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Qualitative performance on multiple random crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab248e8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nimgs = 3\n",
    "ncols = 7\n",
    "nrows = 2 * nimgs\n",
    "sz = 300\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "\n",
    "for img_idx in range(nimgs):\n",
    "    hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "    ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "    ax[2 * img_idx, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "    rect = patches.Rectangle(\n",
    "        (ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    "    )\n",
    "    ax[2 * img_idx, 0].add_patch(rect)\n",
    "    ax[2 * img_idx + 1, 0].imshow(\n",
    "        model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\"\n",
    "    )\n",
    "    add_str(ax[2 * img_idx, 0], \"Full Input Frame\")\n",
    "    add_str(ax[2 * img_idx + 1, 0], \"Random Input Crop\")\n",
    "\n",
    "    ax[2 * img_idx, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    diff = pred2 - pred1\n",
    "    ax[2 * img_idx, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "    ax[2 * img_idx + 1, 4].imshow(\n",
    "        diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    twinx = ax[2 * img_idx, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 1\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "    twinx = ax[2 * img_idx + 1, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 2\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "ax[0, 0].set_title(\"Model Input\", size=15)\n",
    "ax[0, 1].set_title(\"Target\", size=15)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=15)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=15)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=15)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=15)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=15)\n",
    "\n",
    "clean_ax(ax)\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63530a5a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Quantitative performance\n",
    "We evaluate on two metrics, Multiscale SSIM and PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4575b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tar = mean_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "std_tar = std_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "pred_unnorm = pred * std_tar + mean_tar\n",
    "\n",
    "psnr_list = [\n",
    "    avg_range_inv_psnr(highres_data[..., i].copy(), pred_unnorm[..., i].copy())\n",
    "    for i in range(highres_data.shape[-1])\n",
    "]\n",
    "ssim_list = compute_multiscale_ssim(highres_data.copy(), pred_unnorm.copy())\n",
    "print(\"Metric: Ch1\\t Ch2\")\n",
    "print(f\"PSNR  : {psnr_list[0]:.2f}\\t {psnr_list[1]:.2f}\")\n",
    "print(f\"MS-SSIM  : {ssim_list[0]:.3f}\\t {ssim_list[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
