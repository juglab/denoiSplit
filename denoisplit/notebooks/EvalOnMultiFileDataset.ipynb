{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two environments(debug and prod). From where you want to fetch the code and data? \n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(DEBUG)\n",
    "%run ./nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stats_'+'_'.join(ckpt_dir.split('/')[-4:]) + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"/home/ashesh.ashesh/training/disentangle/2401/D21-M3-S0-L0/6\"\n",
    "# 211/D3-M3-S0-L0/0\n",
    "# 2210/D3-M3-S0-L0/128\n",
    "# 2210/D3-M3-S0-L0/129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27410ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /home/ubuntu/ashesh/training/disentangle/2209/D3-M9-S0-L0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237569",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from denoisplit.data_loader.multifile_raw_dloader import SubDsetType\n",
    "\n",
    "\n",
    "image_size_for_grid_centers = 64\n",
    "mmse_count = 5\n",
    "custom_image_size = 128\n",
    "subdset_type = None # SubDsetType.OneChannel\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test\n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.sampler_type import SamplerType\n",
    "from denoisplit.core.loss_type import LossType\n",
    "# from denoisplit.core.lowres_merge_type import LowresMergeType\n",
    "from denoisplit.data_loader.multifile_raw_dloader import SubDsetType\n",
    "\n",
    "with config.unlocked():\n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if config.data.data_type == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.Iba1Ki64\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    if config.data.data_type == DataType.TavernaSox2GolgiV2:\n",
    "        config.data.channel_1 = '555-647'\n",
    "        config.data.channel_2 = '555-647'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cbe25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    if dtype == DataType.CustomSinosoid:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "else:\n",
    "    if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "    elif dtype == DataType.Prevedel_EMBL:\n",
    "        data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "    elif dtype == DataType.AllenCellMito:\n",
    "        data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "    elif dtype == DataType.SeparateTiffData:\n",
    "        data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "    elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "        data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "    elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "        data_dir = f'{DATA_ROOT}/pavia2'\n",
    "    elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "    elif dtype == DataType.ShroffMitoEr:\n",
    "        data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "    elif dtype == DataType.HTIba1Ki67:\n",
    "        data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "    elif dtype == DataType.BioSR_MRC:\n",
    "        data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "    elif dtype == DataType.TavernaSox2Golgi:\n",
    "        data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/'\n",
    "    elif dtype == DataType.ExpMicroscopyV2:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/'\n",
    "    elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "        data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "        \n",
    "#     2720*2720: microscopy dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if config.model.model_type not in [ModelType.UNet, ModelType.BraveNet]:\n",
    "#     with torch.no_grad():\n",
    "#         inp, tar = val_dset[0][:2]\n",
    "#         out, td_data = model(torch.Tensor(inp[None]).cuda())\n",
    "#         print(td_data['z'][-1].shape)\n",
    "#         print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = max(len(inp_tmp),3)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(len(inp_tmp)):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "ax[1,0].imshow(tar_tmp[0]+tar_tmp[1])\n",
    "ax[1,1].imshow(tar_tmp[0])\n",
    "ax[1,2].imshow(tar_tmp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.analysis.stitch_prediction import stitch_predictions\n",
    "from denoisplit.analysis.mmse_prediction import get_dset_predictions\n",
    "# from denoisplit.analysis.stitch_prediction import get_predictions as get_dset_predictions\n",
    "\n",
    "pred_tiled, rec_loss, logvar, patch_psnr_tuple = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "if config.data.data_type == DataType.TavernaSox2GolgiV2:\n",
    "    dset_is_input = config.data.channel_1 == config.data.channel_2 and config.data.channel_1 == '555-647'\n",
    "    if dset_is_input:\n",
    "        new_config = deepcopy(config)\n",
    "        new_config.data.channel_1 = 'GT_Cy5'\n",
    "        new_config.data.channel_2 = 'GT_TRITC'\n",
    "        _, val_dset_target = create_dataset(new_config, data_dir, eval_datasplit_type = eval_datasplit_type)\n",
    "    else:\n",
    "        val_dset_target = val_dset\n",
    "else:\n",
    "    val_dset_target = val_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee076ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch wise PSNR, as computed during training [ 4.71 23.01] 13.860000000000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535169c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.where(logvar.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(logvar[::50].squeeze().reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for dset in val_dset_target.dsets:\n",
    "    count += dset.idx_manager.grid_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ad118",
   "metadata": {},
   "outputs": [],
   "source": [
    "count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99234fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_tiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "pred = stitch_predictions(pred_tiled,val_dset, smoothening_pixelcount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09091e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape if isinstance(pred, np.ndarray) else [p.shape for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred[np.isnan(pred)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignores_pixels(pred_frames):\n",
    "    ignored_pixels = 1\n",
    "    while(pred_frames[0,-ignored_pixels:,-ignored_pixels:,].std() ==0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    return ignored_pixels\n",
    "\n",
    "def print_ignored_pixels():\n",
    "    if isinstance(pred, np.ndarray):\n",
    "        ignored_pixels = get_ignores_pixels(pred)\n",
    "    elif isinstance(pred, list):\n",
    "        ignored_pixels = [get_ignores_pixels(p) for p in pred]\n",
    "\n",
    "    print(f'Last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = print_ignored_pixels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8474735",
   "metadata": {},
   "source": [
    "## Ignore the pixels which are present in the last few rows and columns. \n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_ignored_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadedfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(pred, np.ndarray):\n",
    "    if config.data.data_type in [DataType.OptiMEM100_014,\n",
    "                                                        DataType.SemiSupBloodVesselsEMBL, \n",
    "                                                        DataType.Pavia2VanillaSplitting,\n",
    "                                                        DataType.ExpansionMicroscopyMitoTub,\n",
    "                                                        DataType.ShroffMitoEr,\n",
    "                                                        DataType.HTIba1Ki67]:\n",
    "        ignored_last_pixels = 32 \n",
    "    elif config.data.data_type == DataType.BioSR_MRC:\n",
    "        ignored_last_pixels = 44\n",
    "        assert val_dset.get_img_sz() == 64\n",
    "    else:\n",
    "        ignored_last_pixels = 0\n",
    "\n",
    "\n",
    "    assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}'\n",
    "    print(ignored_last_pixels)\n",
    "elif isinstance(pred, list):\n",
    "    ignored_last_pixels = actual_ignored_pixels\n",
    "ignore_first_pixels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = val_dset_target._data if isinstance(pred, np.ndarray) else [val_dset_target.dsets[i]._data for i in range(len(val_dset_target.dsets))]\n",
    "\n",
    "def ignore_pixels(arr):\n",
    "    if ignore_first_pixels:\n",
    "        arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "    if ignored_last_pixels !=0:\n",
    "        if isinstance(arr, np.ndarray):\n",
    "            arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "            return arr\n",
    "        elif isinstance(arr, list):\n",
    "            output_arr = []\n",
    "            for i,a in enumerate(arr):\n",
    "                if ignored_last_pixels[i] !=0:\n",
    "                    output_arr.append(a[:,:-ignored_last_pixels[i],:-ignored_last_pixels[i]] )\n",
    "                else:\n",
    "                    output_arr.append(a)\n",
    "            return output_arr\n",
    "        \n",
    "pred = ignore_pixels(pred)\n",
    "tar = ignore_pixels(tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from denoisplit.analysis.plot_utils import *\n",
    "# def add_pixel_kde(ax,\n",
    "#                   rect: List[float],\n",
    "#                   data1: np.ndarray,\n",
    "#                   data2: Union[np.ndarray, None],\n",
    "#                   min_labelsize: int,\n",
    "#                   color1='r',\n",
    "#                   color2='black',\n",
    "#                   color_xtick='white',\n",
    "#                   label1='Target',\n",
    "#                   label2='Predicted'):\n",
    "#     \"\"\"\n",
    "#     Adds KDE (density plot) of data1(eg: target) and data2(ex: predicted) image pixel values as an inset\n",
    "#     \"\"\"\n",
    "#     inset_ax = add_subplot_axes(ax, rect, facecolor=\"None\", min_labelsize=min_labelsize)\n",
    "    \n",
    "#     inset_ax.tick_params(axis='x', colors=color_xtick)\n",
    "\n",
    "#     sns.kdeplot(data=data1.reshape(-1, ), ax=inset_ax, color=color1, label=label1)\n",
    "#     if data2 is not None:\n",
    "#         sns.kdeplot(data=data2.reshape(-1, ), ax=inset_ax, color=color2, label=label2)\n",
    "#     inset_ax.set_xlim(left=0)\n",
    "#     xticks = inset_ax.get_xticks()\n",
    "#     # inset_ax.set_xticks([xticks[0], xticks[-1]])\n",
    "#     inset_ax.set_xticks([])\n",
    "#     clean_for_xaxis_plot(inset_ax)\n",
    "\n",
    "\n",
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "\n",
    "# inset_rect=[0.1,0.1,0.4,0.2]\n",
    "# inset_min_labelsize=10\n",
    "# color_ch_list=['goldenrod','cyan']\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(15,10),ncols=3,nrows=2)\n",
    "# idx = 8\n",
    "# pred1_crop  = ch1_pred_unnorm[idx,1116:1372,1064:1320].copy()\n",
    "# pred2_crop  = ch2_pred_unnorm[idx,1116:1372,1064:1320].copy()\n",
    "# pred1_crop[pred1_crop<0] = 0\n",
    "# pred2_crop[pred2_crop<0] = 0\n",
    "\n",
    "# tar1_crop   =  tar[idx,1116:1372,1064:1320,0]\n",
    "# tar2_crop   =  tar[idx,1116:1372,1064:1320,1]\n",
    "\n",
    "# ax[0,0].imshow(tar1_crop+tar2_crop)\n",
    "# ax[0,1].imshow(tar1_crop)\n",
    "# ax[0,2].imshow(tar2_crop)\n",
    "\n",
    "# ax[1,0].imshow(pred1_crop+pred2_crop)\n",
    "# ax[1,1].imshow(pred1_crop)\n",
    "# ax[1,2].imshow(pred2_crop)\n",
    "# clean_ax(ax)\n",
    "# add_pixel_kde(ax[0,0], inset_rect, \n",
    "#               tar1_crop, \n",
    "#               tar2_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1=color_ch_list[0], color2=color_ch_list[1])\n",
    "\n",
    "# add_pixel_kde(ax[1,1], inset_rect, \n",
    "#               pred1_crop, \n",
    "#               tar1_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1='red', color2=color_ch_list[0])\n",
    "# add_pixel_kde(ax[1,2], inset_rect, \n",
    "#               pred2_crop, \n",
    "#               tar2_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1='red', color2=color_ch_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "def _avg_psnr(target, prediction, psnr_fn):\n",
    "    output = np.mean([psnr_fn(target[i:i + 1], prediction[i:i + 1]).item() for i in range(len(prediction))])\n",
    "    return round(output, 2)\n",
    "\n",
    "\n",
    "def avg_range_inv_psnr(target, prediction):\n",
    "    return _avg_psnr(target, prediction, RangeInvariantPsnr)\n",
    "\n",
    "\n",
    "def avg_psnr(target, prediction):\n",
    "    return _avg_psnr(target, prediction, PSNR)\n",
    "\n",
    "\n",
    "def compute_masked_psnr(mask, tar1, tar2, pred1, pred2):\n",
    "    mask = mask.astype(bool)\n",
    "    mask = mask[..., 0]\n",
    "    tmp_tar1 = tar1[mask].reshape((len(tar1), -1, 1))\n",
    "    tmp_pred1 = pred1[mask].reshape((len(tar1), -1, 1))\n",
    "    tmp_tar2 = tar2[mask].reshape((len(tar2), -1, 1))\n",
    "    tmp_pred2 = pred2[mask].reshape((len(tar2), -1, 1))\n",
    "    psnr1 = avg_range_inv_psnr(tmp_tar1, tmp_pred1)\n",
    "    psnr2 = avg_range_inv_psnr(tmp_tar2, tmp_pred2)\n",
    "    return psnr1, psnr2\n",
    "\n",
    "def avg_ssim(target, prediction):\n",
    "    ssim = [structural_similarity(target[i],prediction[i], data_range=(target[i].max() - target[i].min())) for i in range(len(target))]\n",
    "    return np.mean(ssim),np.std(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean, model.data_std\n",
    "if isinstance(sep_mean, dict):\n",
    "    sep_mean = sep_mean['target']\n",
    "    sep_std = sep_std['target']\n",
    "    \n",
    "sep_mean = sep_mean.squeeze()[None,None,None]\n",
    "sep_std = sep_std.squeeze()[None,None,None]\n",
    "\n",
    "if isinstance(pred, np.ndarray):\n",
    "    tar_normalized = (tar - sep_mean.cpu().numpy())/sep_std.cpu().numpy()\n",
    "    tar1 =tar_normalized[...,0]\n",
    "    tar2 =tar_normalized[...,1]\n",
    "elif isinstance(pred, list):\n",
    "    assert isinstance(tar, list)\n",
    "    assert len(pred) == len(tar)\n",
    "    tar_normalized = [(tar[i]-sep_mean.cpu().numpy())/sep_std.cpu().numpy() for i in range(len(tar))]\n",
    "    tar1 = [tar_normalized[i][...,0] for i in range(len(tar))]\n",
    "    tar2 = [tar_normalized[i][...,1] for i in range(len(tar))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2402048",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(pred, np.ndarray):\n",
    "    q_vals = [0.01, 0.1,0.5,0.9,0.95, 0.99,1]\n",
    "    print('Nuc:', np.quantile(tar_normalized[0][...,0], q_vals).round(2))\n",
    "    print('Tub:', np.quantile(tar_normalized[0][...,1], q_vals).round(2))\n",
    "    print('Nuc:', np.quantile(tar[0][...,0], q_vals))\n",
    "    print('Tub:', np.quantile(tar[0][...,1], q_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([pred[i].shape for i in range(len(pred))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24708c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(12,12),ncols=2,nrows=2)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "if isinstance(pred, np.ndarray):\n",
    "    ax[0,0].imshow(pred[idx,:,:,0])\n",
    "    ax[0,1].imshow(pred[idx,:,:,1])\n",
    "    ax[1,0].imshow(tar1[idx,:,:])\n",
    "    ax[1,1].imshow(tar2[idx,:,:])\n",
    "    print(pred.shape)\n",
    "else:\n",
    "    ax[0,0].imshow(pred[idx][0,:,:,0])\n",
    "    ax[0,1].imshow(pred[idx][0,:,:,1])\n",
    "    ax[1,0].imshow(tar1[idx][0,:,:])\n",
    "    ax[1,1].imshow(tar2[idx][0,:,:])\n",
    "    print(pred[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_preds = []\n",
    "k_preds = 10\n",
    "one_dset = val_dset.dsets[1]\n",
    "for i in range(k_preds):\n",
    "  one_pred_tiled, *_ = get_dset_predictions(model, one_dset,batch_size,\n",
    "                                                num_workers=num_workers,\n",
    "                                                mmse_count=1,\n",
    "                                                  model_type = config.model.model_type,\n",
    "                                                )\n",
    "  one_pred = stitch_predictions(one_pred_tiled,one_dset, smoothening_pixelcount=0)\n",
    "  one_preds.append(one_pred)\n",
    "\n",
    "one_preds = np.concatenate(one_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_preds_unnorm = (one_preds*sep_std.cpu().numpy() + sep_mean.cpu().numpy()).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4546f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.io import imsave\n",
    "# imsave('ch1_samples.tiff', one_preds_unnorm[...,1], plugin='tifffile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(one_preds[1,:,:,0] - one_preds[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(tar1[idx][0].min(), pred[idx][0,...,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc618b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83700dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[idx].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 25\n",
    "vmin1 = int(25 * min(tar1[idx][0].min(), pred[idx][0,...,0].min()))\n",
    "vmax1 = int(25 * max(tar1[idx][0].max(), pred[idx][0,...,0].max()))\n",
    "vmin2 = int(25 * min(tar2[idx][0].min(), pred[idx][0,...,1].min()))\n",
    "vmax2 = int( 25 * max(tar2[idx][0].max(), pred[idx][0,...,1].max()))\n",
    "\n",
    "_,ax = plt.subplots(figsize=(12,8),ncols=3, nrows=2)\n",
    "ax[0,1].imshow(tar1[idx][0]*factor, vmin=vmin1, vmax=vmax1)\n",
    "ax[0,2].imshow(tar2[idx][0]*factor, vmin=vmin2, vmax=vmax2)\n",
    "ax[0,1].set_title('Groundtruth A')\n",
    "ax[0,2].set_title('Groundtruth B')\n",
    "\n",
    "ax[1,0].imshow((tar1[idx][0] + tar2[idx][0])/2)\n",
    "ax[1,0].set_title('Input')\n",
    "ax[1,1].set_title('Prediction A')\n",
    "ax[1,2].set_title('Prediction B')\n",
    "\n",
    "ax[1,1].imshow(pred[idx][0,...,0]*factor, vmin=vmin1, vmax=vmax1)\n",
    "ax[1,2].imshow(pred[idx][0,...,1]*factor, vmin=vmin2, vmax=vmax2)\n",
    "clean_ax(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is already normalized. no need to do it. \n",
    "if isinstance(pred, np.ndarray):\n",
    "    pred1, pred2 = pred[...,0].astype(np.float32), pred[...,1].astype(np.float32)\n",
    "    pred_inp = (pred1 + pred2)/2\n",
    "elif isinstance(pred, list):\n",
    "    pred1_arr = []\n",
    "    pred2_arr = []\n",
    "    pred_inp_arr = []\n",
    "    for i in range(len(pred)):\n",
    "        pred1, pred2 = pred[i][...,0].astype(np.float32), pred[i][...,1].astype(np.float32)\n",
    "        pred_inp = (pred1 + pred2)/2\n",
    "        pred1_arr.append(pred1)\n",
    "        pred2_arr.append(pred2)\n",
    "        pred_inp_arr.append(pred_inp)\n",
    "    pred1 = pred1_arr\n",
    "    pred2 = pred2_arr\n",
    "    pred_inp = pred_inp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(pred, np.ndarray):\n",
    "    ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "    ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "elif isinstance(pred, list):\n",
    "    ch1_pred_unnorm = []\n",
    "    ch2_pred_unnorm = []\n",
    "    for i in range(len(pred)):\n",
    "        ch1_pred_unnorm.append(pred[i][...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy())\n",
    "        ch2_pred_unnorm.append(pred[i][...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar[i].shape, ch1_pred_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.model_type == ModelType.LadderVaeSemiSupervised:\n",
    "    raise NotImplementedError(\"SSIM is incorrectly implemented here.\")\n",
    "    pred_inp = pred[...,2].astype(np.float32)\n",
    "#     tar1 is the input. tar2 is the target. \n",
    "    rmse1 =np.sqrt(((pred1 - tar2)**2).reshape(len(pred1),-1).mean(axis=1))\n",
    "    rmse2 =np.sqrt(((pred_inp - tar1)**2).reshape(len(pred2),-1).mean(axis=1)) \n",
    "\n",
    "    rmse = (rmse1 + rmse2)/2\n",
    "    rmse = np.round(rmse,3)\n",
    "\n",
    "    ssim1_mean, ssim1_std = avg_ssim(tar2, pred1)\n",
    "    ssim2_mean, ssim2_std = avg_ssim(tar1, pred_inp)\n",
    "    \n",
    "    psnr1 = avg_psnr(tar2, pred1)\n",
    "    psnr2 = avg_psnr(tar1, pred_inp)\n",
    "    rinv_psnr1 = avg_range_inv_psnr(tar2, pred1)\n",
    "    rinv_psnr2 = avg_range_inv_psnr(tar1, pred_inp)\n",
    "    \n",
    "elif isinstance(pred, np.ndarray):\n",
    "    rmse1 =np.sqrt(((pred1 - tar1)**2).reshape(len(pred1),-1).mean(axis=1))\n",
    "    rmse2 =np.sqrt(((pred2 - tar2)**2).reshape(len(pred2),-1).mean(axis=1)) \n",
    "\n",
    "    rmse = (rmse1 + rmse2)/2\n",
    "    rmse = np.round(rmse,3)\n",
    "    psnr1 = avg_psnr(tar1, pred1) \n",
    "    psnr2 = avg_psnr(tar2, pred2)\n",
    "    rinv_psnr1 = avg_range_inv_psnr(tar1, pred1)\n",
    "    rinv_psnr2 = avg_range_inv_psnr(tar2, pred2)\n",
    "    ssim1_mean, ssim1_std = avg_ssim(tar[...,0], ch1_pred_unnorm)\n",
    "    ssim2_mean, ssim2_std = avg_ssim(tar[...,1], ch2_pred_unnorm)\n",
    "elif isinstance(pred, list):\n",
    "    ssim1_mean_arr = []\n",
    "    ssim1_std_arr = []\n",
    "    ssim2_mean_arr = []\n",
    "    ssim2_std_arr = []\n",
    "    psnr1_arr = []\n",
    "    psnr2_arr = []\n",
    "    rinv_psnr1_arr = []\n",
    "    rinv_psnr2_arr = []\n",
    "    rmse_arr = []\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        rmse1 =np.sqrt(((pred1[i] - tar1[i])**2).reshape(len(pred1[i]),-1).mean(axis=1))\n",
    "        rmse2 =np.sqrt(((pred2[i] - tar2[i])**2).reshape(len(pred2[i]),-1).mean(axis=1)) \n",
    "\n",
    "        rmse = (rmse1 + rmse2)/2\n",
    "        rmse = np.round(rmse,3)\n",
    "        psnr1 = avg_psnr(tar1[i], pred1[i]) \n",
    "        psnr2 = avg_psnr(tar2[i], pred2[i])\n",
    "        rinv_psnr1 = avg_range_inv_psnr(tar1[i], pred1[i])\n",
    "        rinv_psnr2 = avg_range_inv_psnr(tar2[i], pred2[i])\n",
    "        ssim1_mean, ssim1_std = avg_ssim(tar[i][...,0], ch1_pred_unnorm[i])\n",
    "        ssim2_mean, ssim2_std = avg_ssim(tar[i][...,1], ch2_pred_unnorm[i])\n",
    "        ssim1_mean_arr.append(ssim1_mean)\n",
    "        ssim1_std_arr.append(ssim1_std)\n",
    "        ssim2_mean_arr.append(ssim2_mean)\n",
    "        ssim2_std_arr.append(ssim2_std)\n",
    "        psnr1_arr.append(psnr1)\n",
    "        psnr2_arr.append(psnr2)\n",
    "        rinv_psnr1_arr.append(rinv_psnr1)\n",
    "        rinv_psnr2_arr.append(rinv_psnr2)\n",
    "        rmse_arr.append(rmse)\n",
    "    \n",
    "    ssim1_mean = np.mean(ssim1_mean_arr)\n",
    "    ssim1_std = np.mean(ssim1_std_arr)\n",
    "    ssim2_mean = np.mean(ssim2_mean_arr)\n",
    "    ssim2_std = np.mean(ssim2_std_arr)\n",
    "    psnr1 = np.round(np.mean(psnr1_arr),2)\n",
    "    psnr2 = np.round(np.mean(psnr2_arr),2)\n",
    "    rinv_psnr1 = np.round(np.mean(rinv_psnr1_arr),2)\n",
    "    rinv_psnr2 = np.round(np.mean(rinv_psnr2_arr),2)\n",
    "    rmse = np.mean(rmse_arr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87868b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{custom_image_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "print('Rec Loss',np.round(rec_loss.mean(),3) )\n",
    "print('RMSE', np.mean(rmse1).round(3), np.mean(rmse2).round(3), np.mean(rmse).round(3))\n",
    "print('PSNR', psnr1, psnr2)\n",
    "print('RangeInvPSNR',rinv_psnr1, rinv_psnr2 )\n",
    "print('SSIM',round(ssim1_mean,3), round(ssim2_mean,3),'±',round((ssim1_std + ssim2_std)/2,4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89184290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rec Loss 2.075\n",
    "# RMSE 1.317 1.108 1.043\n",
    "# PSNR 13.11 10.32\n",
    "# RangeInvPSNR 35.09 30.5\n",
    "# SSIM 0.553 0.568 ± 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c559da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_P64_G32_M1_Sk32\n",
    "# Rec Loss -0.45\n",
    "# RMSE 0.218 0.15 0.184\n",
    "# PSNR 31.69 31.57\n",
    "# RangeInvPSNR 31.7 31.6\n",
    "# SSIM 0.757 0.658 ± 0.0033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb5107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lhrt Act*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.model_type == ModelType.LadderVaeSemiSupervised:\n",
    "    from denoisplit.analysis.plot_utils import add_pixel_kde\n",
    "    inset_rect=[0.1,0.1,0.4,0.2]\n",
    "    min_labelsize = 15\n",
    "\n",
    "    nimgs=5\n",
    "    crp_sz = 400\n",
    "    img_sz = 8\n",
    "\n",
    "    _,ax = plt.subplots(figsize=(4*img_sz,img_sz*nimgs),ncols=5,nrows=nimgs)\n",
    "    clean_ax(ax[1:,])\n",
    "    clean_ax(ax[:,1:])\n",
    "    img_idx_list = np.random.permutation(np.arange(len(tar1)))[:nimgs] #[19,23,15,18,4] # \n",
    "    for ax_idx in range(nimgs):\n",
    "        img_idx = img_idx_list[ax_idx]\n",
    "        overlapping_pred = pred1[img_idx] + pred2[img_idx]\n",
    "        overlapping_min = min(tar1[img_idx].min(),overlapping_pred.min())\n",
    "        overlapping_max = max(tar1[img_idx].max(),overlapping_pred.max())\n",
    "\n",
    "        ax[ax_idx,0].imshow(tar1[img_idx])#,vmin=overlapping_min,vmax=overlapping_max)\n",
    "        ax[ax_idx,1].imshow(overlapping_pred)#,vmin=overlapping_min,vmax=overlapping_max)\n",
    "\n",
    "        ch1_min = tar2[img_idx].min()#,pred1[img_idx].min())\n",
    "        ch1_max = tar2[img_idx].max()#,pred1[img_idx].max())\n",
    "        ax[ax_idx,2].imshow(tar2[img_idx])#,vmin=ch1_min,vmax=ch1_max)\n",
    "        ax[ax_idx,3].imshow(pred1[img_idx])#,vmin=ch1_min,vmax=ch1_max)\n",
    "\n",
    "        ax[ax_idx,4].imshow(pred2[img_idx])\n",
    "        ax[ax_idx,0].set_ylabel(f'{img_idx}',fontsize=min_labelsize)\n",
    "\n",
    "        # add_pixel_kde(ax[ax_idx,1],\n",
    "        #               inset_rect,\n",
    "        #               tar1 [img_idx],\n",
    "        #               data2 =overlapping_pred,\n",
    "        #              min_labelsize=min_labelsize)\n",
    "        \n",
    "        # add_pixel_kde(ax[ax_idx,3],\n",
    "        #               inset_rect,\n",
    "        #               tar2 [img_idx],\n",
    "        #               data2 =pred1[img_idx],\n",
    "        #              min_labelsize=min_labelsize)\n",
    "        \n",
    "\n",
    "    ax[0,0].set_title('Inp')\n",
    "    ax[0,1].set_title('Recons')\n",
    "    ax[0,2].set_title('GT 1')\n",
    "    ax[0,3].set_title('Pred 1')\n",
    "    ax[0,4].set_title('Pred 2')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19442f1",
   "metadata": {},
   "source": [
    "### To save to tiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a537930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "# input_pred_unnorm = pred[...,2]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = input_pred_unnorm - ch1_pred_unnorm\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy() #ch2_pred_unnorm - ch2_pred_unnorm.min()\n",
    "\n",
    "# ch1_pred_unnorm = ch1_pred_unnorm.astype(np.int32)\n",
    "# input_pred_unnorm = input_pred_unnorm.astype(np.int32)\n",
    "# ch2_pred_unnorm = ch2_pred_unnorm.astype(np.int32)\n",
    "\n",
    "# data = np.concatenate([val_dset._data[:,:480,:480], ch1_pred_unnorm[...,None],\n",
    "# ch2_pred_unnorm[...,None], input_pred_unnorm[...,None]],\n",
    "# axis=-1)\n",
    "\n",
    "# import tifffile\n",
    "# tifffile.imwrite(\"prediction2.tif\", \n",
    "# np.swapaxes(data[:,None],1,4)[...,0].astype(np.uint16),\n",
    "# imagej=True, \n",
    "# #  metadata={ 'axes': 'ZYXC'}, \n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2806ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_for_one(idx):\n",
    "    print(f'Showing for {idx}')\n",
    "    with torch.no_grad():\n",
    "        inp, tar = val_dset[idx]\n",
    "\n",
    "        inp = torch.Tensor(inp[None])\n",
    "        tar = torch.Tensor(tar[None])\n",
    "        inp = inp.cuda()\n",
    "        x_normalized = model.normalize_input(inp)\n",
    "        tar = tar.cuda()\n",
    "        tar_normalized = model.normalize_target(tar)\n",
    "\n",
    "        recon_img_list = []\n",
    "        for _ in range(5):\n",
    "            if config.model.model_type == ModelType.UNet:\n",
    "                recon_normalized = model(x_normalized)\n",
    "                imgs = recon_normalized\n",
    "            elif config.model.model_type == ModelType.LadderVaeSemiSupervised:\n",
    "                out, td_data = model(x_normalized)\n",
    "                rec_loss, imgs = model.get_reconstruction_loss(out,\n",
    "                                                               x_normalized,\n",
    "                                                               tar_normalized,\n",
    "                                                               return_predicted_img=True)\n",
    "            else:\n",
    "                recon_normalized, td_data = model(x_normalized)\n",
    "                rec_loss, imgs = model.get_reconstruction_loss(recon_normalized, tar_normalized,\n",
    "                                                               return_predicted_img=True)\n",
    "            recon_img_list.append(imgs.cpu().numpy()[0])\n",
    "\n",
    "    _,ax = plt.subplots(figsize=(12,4),ncols=3)\n",
    "    ax[0].imshow(inp[0,0].cpu().numpy())\n",
    "    ax[1].imshow(tar[0,0].cpu().numpy())\n",
    "    if tar.shape[1] ==2:\n",
    "        ax[2].imshow(tar[0,1].cpu().numpy())\n",
    "\n",
    "    _,ax = plt.subplots(figsize=(20,8),ncols=5,nrows=2)\n",
    "    for i in range(5):\n",
    "        ax[0,i].imshow(recon_img_list[i][0])\n",
    "        ax[1,i].imshow(recon_img_list[i][1])\n",
    "\n",
    "show_for_one(np.random.randint(len(val_dset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ecf7e",
   "metadata": {},
   "source": [
    "## Creating tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de631db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdate,rconfig,rid = ckpt_dir.split(\"/\")[-3:]\n",
    "fname_prefix = rdate + '-' + rconfig.replace('-','')[:-2] + '-' + rid\n",
    "fname_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "pred_unnorm = np.concatenate([ch1_pred_unnorm[...,None],\n",
    "                              ch2_pred_unnorm[...,None]],\n",
    "                              axis=-1)\n",
    "for ch_idx in [0,1]:\n",
    "    tif_fname = f'{fname_prefix}_P{custom_image_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}_C{ch_idx}.tif'\n",
    "    tif_fpath=os.path.join('paper_tifs',tif_fname)\n",
    "    if config.data.data_type in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        output = np.concatenate([\n",
    "                            pred_unnorm[None,:50,...,ch_idx],tar[None,:50,...,ch_idx],\n",
    "        ],axis=0)\n",
    "    else:\n",
    "        output = np.concatenate([\n",
    "                                pred_unnorm[:1,...,ch_idx],tar[:1,...,ch_idx],\n",
    "        ],axis=0)\n",
    "    imsave(tif_fpath,output,plugin='tifffile')\n",
    "    print(tif_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lhrt paper_tifs/2211-D8M3S0-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls paper_tifs/2211-D3M3S0-0_P64_G*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp, tar = val_dset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(inp) > 1:\n",
    "    _,ax = plt.subplots(figsize=(10,2.5),ncols=4)\n",
    "    ax[0].imshow(inp[0])\n",
    "    ax[1].imshow(inp[1])\n",
    "    ax[2].imshow(inp[2])\n",
    "    ax[3].imshow(inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fe5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(10,10))\n",
    "# tmp_data =tar_unnorm[idx,:,:,1]\n",
    "# q = np.quantile(tmp_data,0.95)\n",
    "# tmp_data[tmp_data >q] = q\n",
    "# plt.imshow(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,20),ncols=2,nrows=2)\n",
    "ax[0,0].set_title('Channel 1',size=20)\n",
    "ax[0,1].set_title('Channel 2',size=20)\n",
    "ax[0,0].set_ylabel('Target',size=20)\n",
    "ax[1,0].set_ylabel('Predictions',size=20)\n",
    "ax[0,0].imshow(tar_unnorm[idx,:,:,0])\n",
    "ax[0,1].imshow(tar_unnorm[idx,:,:,1])\n",
    "ax[1,0].imshow(pred_unnorm[idx,:,:,0])\n",
    "ax[1,1].imshow(pred_unnorm[idx,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  0#np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,30),ncols=2,nrows=3)\n",
    "ax[0,0].set_title('Target',size=20)\n",
    "ax[0,1].set_title('Prediction',size=20)\n",
    "ax[0,0].set_ylabel('Mixed Input',size=20)\n",
    "ax[1,0].set_ylabel('Channel 1',size=20)\n",
    "ax[2,0].set_ylabel('Channel 2',size=20)\n",
    "sz = 400\n",
    "ax[0,0].imshow(np.mean(tar_unnorm[idx, 1000:1000+sz,400:400+sz], axis=2))\n",
    "ax[0,1].imshow(np.mean(pred_unnorm[idx,1000:1000+sz,400:400+sz], axis=2))\n",
    "\n",
    "ax[1,0].imshow(tar_unnorm[idx, 1000:1000+sz,400:400+sz,0],vmax=126,vmin=88)\n",
    "ax[1,1].imshow(pred_unnorm[idx,1000:1000+sz,400:400+sz,0], vmax=126,vmin=88)\n",
    "\n",
    "ax[2,0].imshow(tar_unnorm[idx, 1000:1000+sz,400:400+sz,1],vmax=126,vmin=78)\n",
    "ax[2,1].imshow(pred_unnorm[idx,1000:1000+sz,400:400+sz,1],vmax=126,vmin=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[idx, 1000:1500,400:900,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa229c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm[idx,1000:1500,400:900,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285b5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f14602",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,30),ncols=2,nrows=3)\n",
    "ax[0,0].set_title('Target',size=20)\n",
    "ax[0,1].set_title('Prediction',size=20)\n",
    "ax[0,0].set_ylabel('Mixed Input',size=20)\n",
    "ax[1,0].set_ylabel('Channel 1',size=20)\n",
    "ax[2,0].set_ylabel('Channel 2',size=20)\n",
    "\n",
    "ax[0,0].imshow(np.mean(tar_unnorm[idx, 1000:1500,400:900], axis=2))\n",
    "ax[0,1].imshow(np.mean(pred_unnorm[idx,1000:1500,400:900], axis=2))\n",
    "\n",
    "ax[1,0].imshow(tar_unnorm[idx, 1000:1500,400:900,0])\n",
    "ax[1,1].imshow(pred_unnorm[idx,1000:1500,400:900,0])\n",
    "\n",
    "ax[2,0].imshow(tar_unnorm[idx, 1000:1500,400:900,1])\n",
    "ax[2,1].imshow(pred_unnorm[idx,1000:1500,400:900,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5306061",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fb49d",
   "metadata": {},
   "source": [
    "## Comparing PSNR with high res data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe03625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.data_split_type import  get_datasplit_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_datasplit_type == DataSplitType.Val:\n",
    "    N = len(pred1)/config.training.val_fraction\n",
    "elif eval_datasplit_type == DataSplitType.Test:\n",
    "    N = len(pred1)/config.training.test_fraction\n",
    "train_idx,val_idx,test_idx = get_datasplit_tuples(config.training.val_fraction,config.training.test_fraction,N,\n",
    "                                          starting_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.tiff_reader import load_tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "highres_actin = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/actin-60x-noise2-highsnr.tif')[...,None]\n",
    "highres_mito = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/mito-60x-noise2-highsnr.tif')[...,None]\n",
    "\n",
    "if eval_datasplit_type == DataSplitType.Val:\n",
    "    highres_data = np.concatenate([highres_actin[val_idx[0]:val_idx[1]],\n",
    "                                   highres_mito[val_idx[0]:val_idx[1]]],\n",
    "                                  axis=-1).astype(np.float32)\n",
    "elif eval_datasplit_type == DataSplitType.Test:\n",
    "    highres_data = np.concatenate([highres_actin[test_idx[0]:test_idx[1]],\n",
    "                                   highres_mito[test_idx[0]:test_idx[1]]],\n",
    "                                  axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d325d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.quantile(highres_data,config.data.clip_percentile)\n",
    "highres_data[highres_data > thresh]=thresh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,8),ncols=2,nrows=2)\n",
    "ax[0,0].imshow(tar_unnorm[5,...,0])\n",
    "ax[0,1].imshow(highres_data[5,...,0])\n",
    "ax[1,0].imshow(tar_unnorm[8,...,1])\n",
    "ax[1,1].imshow(highres_data[8,...,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ddb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PSNR with HighRes', avg_psnr(highres_data[...,0], pred1),avg_psnr(highres_data[...,1], pred2))\n",
    "print('RangeInvPSNR with HighRes', avg_range_inv_psnr(highres_data[...,0], pred1), \n",
    "      avg_range_inv_psnr(highres_data[...,1], pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RangeInvPSNR with HighRes 16.82 18.33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_1_tmp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.psnr import fix_range, zero_mean\n",
    "def fix_range_with_highresdata(pred,tar):\n",
    "    pred_1_tmp = torch.Tensor(pred.reshape(len(pred),-1))\n",
    "    tar_1_tmp = torch.Tensor(tar.reshape(len(tar),-1))\n",
    "    pred_1_tmp = zero_mean(pred_1_tmp)\n",
    "    tar_1_tmp = zero_mean(tar_1_tmp)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    tar_1_tmp = tar_1_tmp / torch.std(tar_1_tmp, dim=1, keepdim=True)\n",
    "    \n",
    "    pred_1_tmp = fix_range(tar_1_tmp,pred_1_tmp)\n",
    "    pred_1_tmp = pred_1_tmp.reshape_as(torch.Tensor(pred))\n",
    "    tar_1_tmp = tar_1_tmp.reshape_as(torch.Tensor(pred))\n",
    "    return pred_1_tmp, tar_1_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3faaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_tmp, tar1_tmp = fix_range_with_highresdata(pred1, highres_data[...,0])\n",
    "pred2_tmp, tar2_tmp = fix_range_with_highresdata(pred2, highres_data[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim1_mean, ssim1_std = avg_ssim(tar1_tmp.numpy(), pred1_tmp.numpy())\n",
    "ssim2_mean, ssim2_std = avg_ssim(tar2_tmp.numpy(), pred2_tmp.numpy())\n",
    "print(ssim1_mean, ssim2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6557f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "ax[0].imshow(pred_1_tmp[0])\n",
    "ax[1].imshow(tar_1_tmp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992749",
   "metadata": {},
   "source": [
    "## Inspecting the performance on grid boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.analysis.stitch_prediction import stitched_prediction_mask\n",
    "\n",
    "\n",
    "skip_boundary_pixel_count = 0\n",
    "for sk_c in [1,16,32,48,56]:\n",
    "    mask = stitched_prediction_mask(val_dset, \n",
    "                                (val_dset._img_sz,val_dset._img_sz), \n",
    "                                skip_boundary_pixel_count, \n",
    "                                sk_c)\n",
    "    mask = ignore_pixels(mask)\n",
    "    psnr1, psnr2 = compute_masked_psnr(mask, tar1,tar2,pred1,pred2)\n",
    "    print(f'[Pad:{val_dset.per_side_overlap_pixelcount()}] SkipCentral', sk_c,\n",
    "          psnr1,psnr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c325b",
   "metadata": {},
   "source": [
    "## Inspecting the performance on central regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_central_pixel_count = 0\n",
    "\n",
    "for sk_b in [1,8,16,20,24]:\n",
    "    mask = stitched_prediction_mask(val_dset, \n",
    "                                (val_dset._img_sz,val_dset._img_sz), \n",
    "                                sk_b, \n",
    "                                skip_central_pixel_count)\n",
    "    mask = ignore_pixels(mask)\n",
    "    psnr1, psnr2 = compute_masked_psnr(mask, tar1,tar2,pred1,pred2)\n",
    "    print(f'[Pad:{val_dset.per_side_overlap_pixelcount()}] SkipBoundary', sk_b, psnr1,psnr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in range(2,202,25):\n",
    "#     print(f'RangeInvPSNR but skipping {w}', avg_range_inv_psnr(np.copy(tar1[:,w:-w,w:-w]), \n",
    "#                                                                np.copy(pred1[:,w:-w,w:-w])),\n",
    "    \n",
    "#                                             avg_range_inv_psnr(np.copy(tar2[:,w:-w,w:-w]), \n",
    "#                                                                np.copy(pred2[:,w:-w,w:-w]).copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff40aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79275615",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1200\n",
    "w = 1200\n",
    "sz = 512\n",
    "x = tar_unnorm[:1,h:h+sz,w:w+sz].mean(axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de600304",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count = 32\n",
    "y1 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]))\n",
    "y2 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]), constant_values=237)\n",
    "y3 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]), mode='linear_ramp', end_values=237)\n",
    "y4 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]),mode='reflect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae212914",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(x, [0,0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "ax[0].imshow(y1[0], )\n",
    "ax[1].imshow(y2[0], )\n",
    "ax[2].imshow(y3[0], )\n",
    "ax[3].imshow(y4[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(tar_unnorm[0,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(tar_unnorm[0,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d967c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(tar_unnorm[-1,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(tar_unnorm[-1,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(pred_unnorm[0,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(pred_unnorm[0,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "# import seaborn.apionly as sns\n",
    "\n",
    "_,ax = plt.subplots(figsize=(20,4))\n",
    "sns.histplot(tar_unnorm[-1,:,:].mean(axis=2).reshape(-1,))\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30034a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp, tar = val_dset[11060]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "# ax[0].imshow(inp[0])\n",
    "# ax[1].imshow(inp[1])\n",
    "# ax[2].imshow(inp[2])\n",
    "# ax[3].imshow(inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "# ax[0].imshow(tar[0])\n",
    "# ax[1].imshow(tar[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f3b3a",
   "metadata": {},
   "source": [
    "## Inspecting the difference in behaviour when different sized inputs are passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def compute_centered_diff(big,small):\n",
    "    pad = (big.shape[-1] - small.shape[-1])//2\n",
    "#     import pdb;pdb.set_trace()\n",
    "    return big[:,:,pad:-pad,pad:-pad] - small\n",
    " \n",
    "old_img_sz = val_dset.get_img_sz()\n",
    "val_dset.set_img_sz(128)\n",
    "inp2, tar2 = val_dset[10000]\n",
    "with torch.no_grad():\n",
    "    bu_values2 = model.bottomup_pass(torch.Tensor(inp2[None]).cuda())\n",
    "\n",
    "val_dset.set_img_sz(256)\n",
    "inp3, tar3 = val_dset[10000]\n",
    "with torch.no_grad():\n",
    "    bu_values3 = model.bottomup_pass(torch.Tensor(inp3[None]).cuda())\n",
    "\n",
    "diff = (bu_values2[0] - bu_values3[0][:,:,32:-32,32:-32]).cpu().numpy()\n",
    "sns.histplot(diff.reshape(-1,))\n",
    "\n",
    "##LOOKING AT bu_values\n",
    "idx=1\n",
    "diff = compute_centered_diff(bu_values3[idx],bu_values2[idx]).cpu().numpy()\n",
    "_,ax =plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(diff[0,0])\n",
    "\n",
    "## Looking at the difference in prediction.\n",
    "with torch.no_grad():\n",
    "    out2,_ = model(torch.Tensor(inp2[None,]).cuda())\n",
    "    out3,_ = model(torch.Tensor(inp3[None,]).cuda())\n",
    "    img2 = get_img_from_forward_output(out3,model)\n",
    "    img3 = get_img_from_forward_output(out2,model)\n",
    "diff = compute_centered_diff(img2,img3)\n",
    "_,ax =plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(diff[0,1].cpu().numpy())\n",
    "val_dset.set_img_sz(old_img_sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c561780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoisplit.core.tiff_reader import load_tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/actin-60x-noise2-highsnr.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(img[0])\n",
    "ax[1].imshow(img[1])\n",
    "ax[2].imshow(img[2])\n",
    "ax[3].imshow(img[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 =load_tiff('/home/ashesh.ashesh/data/microscopy/OptiMEM100x014.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b01f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(img2[0,...,0])\n",
    "ax[1].imshow(img2[1,...,0])\n",
    "ax[2].imshow(img2[2,...,0])\n",
    "ax[3].imshow(img2[3,...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11536e0",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = val_dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551123e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(3,3))\n",
    "plt.imshow(tar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b01d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf517837",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.436+0.810)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
